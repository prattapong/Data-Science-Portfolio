{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Rattapong.Pojpatin\\\\OneDrive - Interpublic\\\\Documents\\\\GitHub\\\\Data-Science-Portfolio\\\\Projects\\\\Generative AI'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf_file(data):\n",
    "    loader = DirectoryLoader(\n",
    "        data,\n",
    "        glob = '*.pdf',\n",
    "        loader_cls = PyPDFLoader\n",
    "    )\n",
    "\n",
    "    documents = loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf_file(data = 'Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = 500,\n",
    "        chunk_overlap = 20\n",
    "    )\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Text Chucks: 5860\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(f'Length of Text Chucks: {len(text_chunks)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name = 'sentence-transformers/all-MiniLM-L6-v2') # 384 dimensional vector\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rattapong.Pojpatin\\AppData\\Local\\Temp\\ipykernel_36120\\3533957157.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name = 'sentence-transformers/all-MiniLM-L6-v2') # 384 dimensional vector\n",
      "c:\\Users\\Rattapong.Pojpatin\\Anaconda3\\envs\\appbot\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "query_result = embeddings.embed_query('Test')\n",
    "print(len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY')\n",
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')\n",
    "HUGGINGFACE_API_KEY = os.environ.get('HUGGINGFACE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone.grpc import PineconeGRPC as Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "import os\n",
    "\n",
    "pc = Pinecone(api_key = PINECONE_API_KEY)\n",
    "\n",
    "index_name = 'testbot'\n",
    "\n",
    "# pc.create_index(\n",
    "#     name = index_name,\n",
    "#     dimension = 384,\n",
    "#     metric = 'cosine',\n",
    "#     spec = ServerlessSpec(\n",
    "#         cloud = 'aws',\n",
    "#         region = 'us-east-1'\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PINECONE_API_KEY'] = PINECONE_API_KEY\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "os.environ['huggingfacehub_api_token'] = HUGGINGFACE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents = text_chunks,\n",
    "    index_name = index_name,\n",
    "    embedding = embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name = index_name,\n",
    "    embedding = embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type = 'similarity', search_kwargs = {'k': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_doc = retriever.invoke('What is Acne?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "from transformers import pipeline\n",
    "from langchain.llms import HuggingFaceHub\n",
    "\n",
    "# llm = OpenAI(temperature = 0.4, max_tokens = 500)\n",
    "# hf_pipeline = pipeline(\n",
    "#     \"text-generation\", \n",
    "#     model=\"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "#     use_auth_token=True\n",
    "# )\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.1\", \n",
    "    model_kwargs={\n",
    "        \"temperature\": 0.4, \n",
    "        \"max_new_tokens\": 500,\n",
    "        \"do_sample\": True,  # Ensure sampling is enabled\n",
    "        \"return_full_text\": False  # Avoid repeating input\n",
    "    },\n",
    "    huggingfacehub_api_token=HUGGINGFACE_API_KEY  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import re\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer the question. \"\n",
    "    \"You must use ONLY the provided retrieved context to answer the question.  \"\n",
    "    \"- If the answer is NOT in the context, respond with: **'I don’t know.'** \"\n",
    "    \"- Do NOT generate any additional information.  \"\n",
    "    \"- If the answer is in the context, answer concisely with no more than 3 sentences.  \"\n",
    "    \"Use three sentences maximum and keep the answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"Context: {context}\"\n",
    ")\n",
    "\n",
    "# system_prompt = \"\"\"You are an assistant for question-answering tasks.  \n",
    "# You must use ONLY the provided retrieved context to answer the question.  \n",
    "\n",
    "# - If the answer is in the context, answer concisely.  \n",
    "# - If the answer is NOT in the context, respond with: **\"I don’t know.\"**  \n",
    "# - Do NOT generate any additional information.  \n",
    "\n",
    "# Context:  \n",
    "# {context}  \n",
    "\n",
    "# Question: {input}  \n",
    "# Answer:\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# system_prompt = (\n",
    "#     \"You are an assistant for question-answering tasks. \"\n",
    "#     \"Use the following pieces of retrieved context to answer the question. \"\n",
    "#     \"If the answer is not in the retrieved context, say: 'I don't know.' \"\n",
    "#     \"Use three sentences maximum and keep the answer concise.\"\n",
    "#     \"\\n\\n\"\n",
    "#     \"{context}\\n\\n\"\n",
    "#     \"User: {input}\\n\"\n",
    "#     \"Assistant:\"\n",
    "# )\n",
    "\n",
    "# prompt = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\"system\", system_prompt),\n",
    "#         (\"human\", \"{input}\")\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# system_prompt = \"\"\"You are an assistant for question-answering tasks. \n",
    "# Use only the following retrieved context to answer the user's question. \n",
    "# If the answer is not in the retrieved context, say: 'I don't know.' \n",
    "# Keep your answer concise and limited to three sentences. \n",
    "\n",
    "# Context: {context}\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"assistant\", \"\")  # Ensure the model knows to generate after this\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rattapong.Pojpatin\\Anaconda3\\envs\\appbot\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"Who is Harry Potter?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I don’t know.\n"
     ]
    }
   ],
   "source": [
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is Covariance?',\n",
       " 'context': [Document(id='8d64c95d-96b2-4944-b56e-41ab17845215', metadata={'page': 451.0, 'page_label': '452', 'source': 'Data\\\\Medical_book.pdf'}, page_content='American Medical Association. 515 N. State St., Chicago, IL\\n60612. (312) 464-5000. <http://www.ama-assn.org>.\\nJoseph Knight, PA\\nBalance and coordination tests\\nDefinition\\nBalance is the ability to maintain a position. Coordi-\\nnation is the capacity to move through a complex set of\\nmovements. Balance and coordination depend on the\\ninteraction of multiple body organs and systems includ-\\ning the eyes, ears, brain and nervous system, cardiovas-\\ncular system, and muscles. Tests or examination of any'),\n",
       "  Document(id='43aaf717-1029-453b-a283-366e476baa32', metadata={'page': 451.0, 'page_label': '452', 'source': 'Data\\\\Medical_book.pdf'}, page_content='American Medical Association. 515 N. State St., Chicago, IL\\n60612. (312) 464-5000. <http://www.ama-assn.org>.\\nJoseph Knight, PA\\nBalance and coordination tests\\nDefinition\\nBalance is the ability to maintain a position. Coordi-\\nnation is the capacity to move through a complex set of\\nmovements. Balance and coordination depend on the\\ninteraction of multiple body organs and systems includ-\\ning the eyes, ears, brain and nervous system, cardiovas-\\ncular system, and muscles. Tests or examination of any'),\n",
       "  Document(id='3801b770-761a-43ea-b659-09f6ee3d5c9e', metadata={'page': 310.0, 'page_label': '311', 'source': 'Data\\\\Medical_book.pdf'}, page_content='Bruxism—Compulsive grinding or clenching of the\\nteeth, especially at night.\\nCarbon monoxide —A colorless, odorless, highly\\npoisonous gas.\\nCentral nervous system —The brain, spinal cord\\nand nerves throughout the body.\\nChronic—A word used to describe a long-lasting\\ncondition. Chronic conditions often develop gradu-\\nally and involve slow changes.\\nHallucination —A false or distorted perception of\\nobjects, sounds, or events that seems real. Hallucina-')],\n",
       " 'answer': ' Covariance is a statistical measure that expresses the average product of deviations from the mean for two variables.'}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved Docs:\n",
      " [Document(id='16bba5e4-6042-43ec-9377-4028e4130a5d', metadata={'page': 111.0, 'page_label': '112', 'source': 'Data\\\\Medical_book.pdf'}, page_content='quite low in alcoholic patients, and deficiency of thiamine\\nis responsible for the Wernicke-Korsakoff syndrome.\\nAfter cessation of drinking has been accomplished,\\nthe next steps involve helping the patient avoid ever tak-\\ning another drink. This phase of treatment is referred to\\nas rehabilitation . The best programs incorporate the\\nfamily into the therapy, because the family has undoubt-\\nedly been severely affected by the patient’s drinking.'), Document(id='f58170a9-5941-4684-9cf9-0c1ddc2c5dc4', metadata={'page': 111.0, 'page_label': '112', 'source': 'Data\\\\Medical_book.pdf'}, page_content='quite low in alcoholic patients, and deficiency of thiamine\\nis responsible for the Wernicke-Korsakoff syndrome.\\nAfter cessation of drinking has been accomplished,\\nthe next steps involve helping the patient avoid ever tak-\\ning another drink. This phase of treatment is referred to\\nas rehabilitation . The best programs incorporate the\\nfamily into the therapy, because the family has undoubt-\\nedly been severely affected by the patient’s drinking.'), Document(id='6be2bd54-a681-472c-954f-f86fb5b97273', metadata={'page': 414.0, 'page_label': '415', 'source': 'Data\\\\Medical_book.pdf'}, page_content='Medicine which he founded in the early 1980s. The center\\nis located at 152 E. 55th St., New York, NY 10022.\\n(AP/Wide World Photos. Reproduced by permission.)\\nGEM - 0001 to 0432 - A  10/22/03 1:43 PM  Page 401')]\n"
     ]
    }
   ],
   "source": [
    "retrieved_docs = retriever.invoke(\"Who is Harry Potter?\")\n",
    "print(\"Retrieved Docs:\\n\", retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "appbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
